**单点Redis问题**

* **数据丢失问题：**实现Redis数据持久化
* 存储能力问题：搭建分片集群，利用插槽机制实现动态扩容
* 并发能力问题：搭建主从集群，实现读写分离
* **故障恢复问题：**利用哨兵机制，实现健康检测和自动恢复

### 一、Redis持久化

* RDB持久化
* AOF持久化

RDB全称Redis Database Backup file（Redis数据备份文件），也叫Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。（停机时默认保存数据，宕机不算）

```sh
redis-cli # 启动Redis客户端
save # 有Redis主进程来执行RDB，会阻塞所有命令，不建议使用
bgsave # 开启子进程执行RDB，避免主进程收到影响
```

**RDB配置**

Redis内部触发RDB机制的配置（在redis.conf文件里）

```shell
# 900秒内，如果至少有一个key被修改，则执行bgsave，如果是 save "" 则表示禁用RDB
save 900 1
```

redis.conf的其他配置

```shell
# 是否压缩，建议不开启，压缩会消耗CPU，而磁盘不值钱
rdbcompression yes

# RDB文件名称
dbfilename dump.rdb

# 文件保存的路径目录
dir ./ # 表示保存在当前目录
```

RDB的异步持久化过程：bgsave开始时会fork主进程得到子进程，子进程**共享**主进程的内存数据。完成fork后读取内存数据并写入RDB文件

fork采用的是copy-on-write技术：

* 当主进程执行读操作时，访问共享内存
* 当主进程执行写操作时，则会拷贝一份数据，执行写操作

比如：共享内存有数据1、数据2。这份共享内存会处于read-only状态。当需要写入数据时，会拷贝一份新的数据B（包含数据1，数据2全部数据），然后再写入到数据副本里，当写入完成时，副本数据则变为共享数据，原数据就不用了（新RDB文件替换就RDB文件）。

**总结：**

* **RDB方式bgsave基本流程：**
  1. fork主进程得到一个子进程
  2. 子进程读取内存数据并写入新的RDB文件
  3. 用新的RDB文件替换旧的RDB文件
* RDB默认服务停止时执行
* RDB缺点：
  1. RDB执行间隔时间长，两次RDB之间写入数据有丢失风险
  2. fork子进程、压缩、写出RDB文件比较费时



#### AOF

AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看作是命令日志文件。

AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF:

```shell
# 是否开启AOF功能，默认是no
appendonly no
# AOF文件名称
appendfilename "appendonly.aof"
```

AOF的命令记录频率的修改也可在redis.conf文件配置

```shell
# 表示每执行一次写命令，立即记录到AOF文件（主进程来完成，最安全，效率也是最差的）
appendfsync always
# 写命令执行完先放入AOF缓冲区，然后每隔一秒将缓冲区数据写到AOF文件，是默认方案
appendsync everysec
# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘（性能最好，安全性最低）
appendsync no
```

因为AOF是记录命令，AOF文件会比RDB文件大许多。而且**AOF会记录对同一个key的多次写操作**，但只有最后一次写操作才有意义。通过执行**bgrewriteaof**命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。

Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置

```shell
# AOF文件比上次文件，增长超过多少百分比会触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写
auto-aof-rewrite-min-size 64mb
```

RDB与AOF对比

**·                                     RDB                                                      AOF**

持久化方式            定时对整个内容做快照                  记录每一次执行命令

数据完整性            不完整，两次备份之间会丢失      相对完整，取决于刷盘策略

文件大小                会有压缩，文件体积小                 记录命令，文件体积很大

宕机恢复速度        很快                                                慢

数据恢复优先级    低，因为数据完整性不如AOF      高，因为数据完整性更高

系统资源占用        高，大量CPU和内存消耗              低，主要是磁盘io资源，但AOF重写时会占                                                             用大量cup和内存资源

使用场景                 可以容忍分钟数据丢失，追求更快启动速度         对数据安全性要求较高



### 二、Redis主从集群

* 搭建主从结构
* 主从数据同步原理

**Redis集群搭建**

1. 恢复redis.conf文件原始配置

   将其中持久化模式改为默认的RDB模式，AOF保持关闭状态

2. 复制多个Redis文件用于配置集群

3. 修改redis.conf中端口的配置，并且将每个redis的RDB文件保存位置修改为自己所在的目录

4. 修改每个实例的声明ip

   虚拟机本身有多个ip，为了避免将来混乱，我们需要再redis.conf文件中指定每一个实例的绑定ip信息，格式如下：

   ```shell
   replica-announce-ip 192.168.40.132
   ```

**开启主从关系**

配置主从可以使用 replicaof 或者 slaveof （5.0以前）命令

有临时和永久两种模式

* 修改配置文件（永久）

  在redis.conf中添加一行配置：slaveof <masterip> <masterport>

* 使用redis.cli客户端连接到redis服务，执行slaveof命令（重启失效）

```shell
# 连接7002
redis.cli -p 7002
# 执行slave
slaveof 192.168.40.132 7001

# 连接7003
redis.cli -p 7003
# 执行slave
slaveof 192.168.40.132 7001
```

**主从搭建完成**



#### 数据同步原理

#### 全量同步

主从第一次同步是全量同步

**第一阶段：**

* slave请求数据同步
* master判断是否是第一次同步
* 是第一次，返回master的数据版本信息
* slave保存版本信息

**第二阶段：**

* master执行bgsave，生成RDB（同时，记录生成RDB期间的所有命令到repl_baklog中的命令）
* master发送RDB文件
* slave清空本地数据，加载RDB文件
* master发送repl_baklog中的命令
* slave执行接受到的命令

完成同步

**master如何判断slave是不是第一次来同步数据？（有两个重要概念）**

* Replication Id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid
* offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。（slave的offset<=master）

因此slave做数据同步，必须向master声明自己的replication和offset，master才可以判断到底需要同步那些数据

master不能简单根据offset是否等于0来判断slave是不是第一次来同步数据。因为slave可能之前同步了其他master的数据。需要根据Replication Id来判断



#### 增量同步（如果slave重启后，则执行增量同步）

**第一阶段：**

* slave psync replid offset
* master判断请求replid是否一致
* master不是第一次，回复continue

**第二阶段：**

* master去repl_baklog中获取offset后的数据
* master发送offset后的命令
* slave 执行命令

**注意：**repl_baklog大小有上限，写满后会覆盖最早的数据。如果slave断开时间过久，导致数据被覆盖，则无法实现增量同步，只能再次全量同步



**Redis主从集群优化**



* 在master中配置repl_diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。（适用于磁盘慢，网络快）
* Redis单节点上内存占用不要太大，减少RDB导致过多的磁盘IO
* 适当提高repl_baklog的大小，发现slave宕机后尽快实现故障恢复（尽可能避免全量同步）

* 限制一个master上的slave节点的数量，如果实在太多slave，则可以采用主-从-从链式结构，减少master压力（即master的slave作为另一个slave的master）



### 三、Redis哨兵机制

* 哨兵的作用与原理
* 搭建哨兵集群
* Redis Template的哨兵模式

#### 哨兵的作用：

Redis提供了哨兵（sentinel）机制来实现主从集群的自动故障恢复。

* **监控：**sentinel会不断检查你的master和slave健康状态
* **自动故障恢复：**如果master故障，sentinel会将一个slave升级为master。当故障实例恢复后也以新的master为主
* **通知：**sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新消息推送给Redis客户端

**服务状态监控：**sentinel基于心跳机制检测服务状态，每隔一秒向集群的每个实例发送一个ping命令

* 主观下线：如果某个sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线
* 客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好设置为sentinel实例数量的一半



**选举新的master**

一旦发现master故障，sentinel需要在slave中选举一个作为新的master，选择依据如下：

* 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds*10），则会排除该节点
* 然后判断slave节点的slave-priority值，值越小优先级越高，如果是0则永远不参与选举
* 如果slave-priority值一样，则判断slave节点的offset值，值越大说明数据越新，优先级越高（主要）
* 最后是判断slave节点的运行id大小，越小优先级越高



**如何实现故障转移**

当选中一个slave为新的master后，故障转移步骤如下（假设7002为新的master）：

* sentinel给备选slave节点（7002）发送slaveof no one命令，让该节点成为新的master
* sentinel给其他所有slave发送slave of 102.168.40.132 7002命令，让这些slave成为新的master的从节点，开始从新的master上同步数据
* 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成新master的slave节点



#### 搭建哨兵集群

**准备实例和配置**

要在同一台虚拟机开启三个实例，必须准备三份不同的配置文件和目录，配置文件所在目录也就是工作目录。我们创建三个文件夹s1、s2、s3。

```shell
# 进入/tmp目录
cd /tmp
# 创建目录
mkdir s1 s2 s3
```

然后再s1目录创建一个sentinel.conf文件（不需要单独下载，自己创建即可），添加下面内容（s2、s2类似）

```shell
# 当前sentinel实例的端口
port 27001 
sentinel announce-ip 192.168.40.132
# 指定主节点信息
# mymaster：主节点名称，自定义
# 192.168.40.132 7001：主节点ip和端口
# 2：选举master时的quorum值
sentinel monitor mymaster 192.168.40.132 7001 2 
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 60000
dir "/tmp/s1"
```

打开3个ssh窗口，分别启动3个redis实例

```shell
redis-sentinel s1/sentinel.conf
```



#### RedisTemplate的哨兵模式

在sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis客户端需要感知这个变化并及时更新连接信息。spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。

```java
    @Autowired
    private StringRedisTemplate redisTemplate;

    @GetMapping("/get/{key}")
    public String hi(@PathVariable String key) {
        return redisTemplate.opsForValue().get(key);
    }

    @GetMapping("/set/{key}/{value}")
    public String hi(@PathVariable String key, @PathVariable String value) 	   {
        redisTemplate.opsForValue().set(key, value);
        return "success";
    }
```

1. 在pom文件中引入redis的start依赖：

   ```java
   <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-data-redis</artifactId>
   </dependency>
   ```

2. 在配置文件application.yml中指定sentinel相关信息

   ```yaml
   spring:
     redis:
       sentinel:
         master: mymaster # 指定master名称
         nodes: # 指定redis-sentinel集群信息
           - 192.168.40.132:27001
           - 192.168.40.132:27002
           - 192.168.40.132:27003
   ```

**配置读写分离**

* MASTER：从主节点读取
* MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica
* REPLICA：从slave（replica）节点读取
* REPLICA_PREFERRED：优先从slave节点读取，所有slave不可用才读取master

在启动类里配置读写分离

```java
    @Bean
    public LettuceClientConfigurationBuilderCustomizer lettuceClientConfigurationBuilderCustomizer(){
        return new LettuceClientConfigurationBuilderCustomizer() {
            @Override
            public void customize(LettuceClientConfiguration.LettuceClientConfigurationBuilder clientConfigurationBuilder) {
                clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
            }
        };
    }

//匿名内部类格式
    @Bean
    public LettuceClientConfigurationBuilderCustomizer 						lettuceClientConfigurationBuilderCustomizer(){
        return clientConfigurationBuilder -> 									clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
    }
```



#### redis分片集群（应对写的高并发和海量数据存储,且自带哨兵机制，不需要自己配置）

* 搭建分片集群
* 散列插槽
* 集群伸缩
* 故障转移
* Redis Template访问分片集群



**分片集群特征：**

* 集群中有多个master，每个master保存不同的数据
* 每个master都可以有多个slave节点
* master之间通过ping监测彼此健康状态
* 客户端请求可以访问任意节点，最终都会被转发到正确节点



**分片集群搭建（三个master，每个master一个slave）**

master：7001、7002、7003

slave：8001、8002、8003

```shell
# 进入/tmp目录
cd /tmp
# 删除就目录，避免配置干扰
rm -rf 7001 7002 7003
# 创建目录
mkdir 7001 7002 7003 8001 8002 8003
```

在/tmp下准备新的redis.conf文件

```shell
port 7001
# 开启集群功能
cluster-enabled yes
# 集群配置文件名称，不需要我们创建，有redis自己维护，但需要指明文件位置
cluster-config-file /tmp/7001/nodes.conf
# 集群心跳失败的超时时间
cluster-node-timeout 5000
# 持久化文件存放目录
dir /tmp/7001
# 绑定地址（任何人都可访问）
bind 0.0.0.0
# 让redis后台运行
daemonize yes
# 注册的实例ip
replica-announce-ip 192.168.40.132
# 保护模式
protected-mode no
# 数据库数量
databases 1
# 日志
logfile /tmp/7001/run.log
```

把配置文件修改下端口并复制到六个redis中

分别启动redis

```shell
redis-server 7001/redis.conf
```

(如果要关闭所有命令使用如下)

```shell
printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t redis-cli -p {} shutdown
```

配置主从

```shell
redis-cli --cluster create --cluster-replicas 1 192.168.40.132 7001 192.168.40.132 7002 192.168.40.132 7003 192.168.40.132 8001 192.168.40.132 8001 192.168.40.132 8001
```

命令说明：

* redis-cli --cluster或者 ./redis-trib.rb：代表集群操作

* create：代表创建集群
* --replicas 1：或者--cluster-replicas 1：指定集群中每个master副本数量为1，此时节点总数%（replica+1）得到的就是master的数量。因此节点列表中前n个就是master，其余的为slave，**随机分配到不同的master**



**散列插槽**

redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息

数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分为两种情况

* key中包含 "{}" ，且key中至少包含一个字符，"{}" 中部分就是有效部分
* key中不包含 "{}" ，整个key都是有效部分

例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个Hash值，然后对16384取余，得到的结果就是slot值



**集群伸缩**

**案例：**向集群中添加一个新的master节点，并向其中存放数据num=10

* 启动一个新的redis实例，端口为7004
* 添加7004到之前的集群，并作为一个master节点
* 给7004节点分配插槽，使得num这个key可以存储到7004

1. 创建7004文件夹，并将redis.conf配置拷贝到该文件，注意修改配置文件端口

   ```shell
   mkdir 7004
   cp redis.conf 7004
   ```

2. 启动7004

   ```shell
   redis-server 7004/redis.conf
   ```

3. 添加节点（此时7004还没有任何插槽）

   ```shell
   redis-cli --cluster add-node 192.168.40.132:7004 192.168.40.132:7001
   ```

4. 重新分配插槽

   ```shell
   redis-cli --cluster reshard 192.168.40.132:7001
   # 然后系统会询问你需要移动多少个插槽
   3000 # 3000个
   # 然后系统会问你移动到哪
   此处就输入7004前面那一长串id
   # 然后系统问你从哪作为数据源拷贝
   此处输入7001前面那一长串id # 因为num这个key在7001上位于2000多位
   # 然后输入done、yes
   done
   yes
   ```

**数据迁移**

利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover这个命令的slave上。实现无感知的数据迁移。

1. slave节点告诉master要进行数据迁移（取代master），**master节点拒绝一切客户端请求**
2. master返回当前数据offset给slave
3. slave等待数据offset与master一致
4. slave开始故障转移
5. slave标记自己为master，并广播故障转移的结果

6. **master收到广播，开始处理客户端请求**





